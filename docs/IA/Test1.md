# üß† Test 1 - Classification d'images

## üìã Objectif du test

D√©velopper et tester un mod√®le de classification d'images pour la reconnaissance d'objets dans notre environnement robotique.

## üéØ Crit√®res de r√©ussite

- **Pr√©cision** : \>95% sur le dataset de test
- **Temps d'inf√©rence** : \<100ms par image
- **Robustesse** : \>90% sur donn√©es bruit√©es
- **G√©n√©ralisation** : \>85% sur donn√©es non vues

## üõ†Ô∏è Environnement technique

### Frameworks utilis√©s
- **TensorFlow** : 2.13.0
- **Keras** : 2.13.1
- **OpenCV** : 4.8.0
- **NumPy** : 1.24.3
- **Matplotlib** : 3.7.2

### Configuration mat√©rielle
```yaml
Hardware:
  GPU: NVIDIA RTX 3080
  RAM: 32GB
  CPU: Intel i7-10700K
  Storage: 1TB SSD
```

## üìä Proc√©dure de test

### √âtape 1 : Pr√©paration des donn√©es
```python
import tensorflow as tf
from tensorflow import keras
import numpy as np
import cv2
from sklearn.model_selection import train_test_split

# Configuration des param√®tres
IMG_SIZE = 224
BATCH_SIZE = 32
EPOCHS = 50
LEARNING_RATE = 0.001

# Chargement du dataset
def load_dataset(data_path):
    """Charge et pr√©processe le dataset"""
    images = []
    labels = []
    
    for class_name in os.listdir(data_path):
        class_path = os.path.join(data_path, class_name)
        for img_name in os.listdir(class_path):
            img_path = os.path.join(class_path, img_name)
            img = cv2.imread(img_path)
            img = cv2.resize(img, (IMG_SIZE, IMG_SIZE))
            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
            images.append(img)
            labels.append(class_name)
    
    return np.array(images), np.array(labels)

# Preprocessing des donn√©es
def preprocess_data(images, labels):
    """Preprocessing et augmentation des donn√©es"""
    # Normalisation
    images = images.astype('float32') / 255.0
    
    # Encodage des labels
    label_encoder = LabelEncoder()
    labels_encoded = label_encoder.fit_transform(labels)
    labels_categorical = keras.utils.to_categorical(labels_encoded)
    
    return images, labels_categorical, label_encoder
```

### √âtape 2 : Architecture du mod√®le
```python
def create_model(input_shape, num_classes):
    """Cr√©e le mod√®le de classification"""
    base_model = keras.applications.MobileNetV2(
        input_shape=input_shape,
        include_top=False,
        weights='imagenet'
    )
    
    # Gel des couches de base
    base_model.trainable = False
    
    # Ajout des couches personnalis√©es
    model = keras.Sequential([
        base_model,
        keras.layers.GlobalAveragePooling2D(),
        keras.layers.Dropout(0.2),
        keras.layers.Dense(128, activation='relu'),
        keras.layers.Dropout(0.2),
        keras.layers.Dense(num_classes, activation='softmax')
    ])
    
    return model

# Compilation du mod√®le
model = create_model((IMG_SIZE, IMG_SIZE, 3), num_classes)
model.compile(
    optimizer=keras.optimizers.Adam(learning_rate=LEARNING_RATE),
    loss='categorical_crossentropy',
    metrics=['accuracy', 'top_3_accuracy']
)
```

### √âtape 3 : Entra√Ænement du mod√®le
```python
# Callbacks pour l'entra√Ænement
callbacks = [
    keras.callbacks.EarlyStopping(
        monitor='val_accuracy',
        patience=10,
        restore_best_weights=True
    ),
    keras.callbacks.ReduceLROnPlateau(
        monitor='val_loss',
        factor=0.5,
        patience=5,
        min_lr=1e-7
    ),
    keras.callbacks.ModelCheckpoint(
        'best_model.h5',
        monitor='val_accuracy',
        save_best_only=True
    )
]

# Entra√Ænement
history = model.fit(
    train_images, train_labels,
    validation_data=(val_images, val_labels),
    epochs=EPOCHS,
    batch_size=BATCH_SIZE,
    callbacks=callbacks,
    verbose=1
)
```

### √âtape 4 : √âvaluation du mod√®le
```python
def evaluate_model(model, test_images, test_labels):
    """√âvalue les performances du mod√®le"""
    # Pr√©dictions
    predictions = model.predict(test_images)
    predicted_classes = np.argmax(predictions, axis=1)
    true_classes = np.argmax(test_labels, axis=1)
    
    # M√©triques
    accuracy = accuracy_score(true_classes, predicted_classes)
    precision = precision_score(true_classes, predicted_classes, average='weighted')
    recall = recall_score(true_classes, predicted_classes, average='weighted')
    f1 = f1_score(true_classes, predicted_classes, average='weighted')
    
    # Matrice de confusion
    cm = confusion_matrix(true_classes, predicted_classes)
    
    return {
        'accuracy': accuracy,
        'precision': precision,
        'recall': recall,
        'f1_score': f1,
        'confusion_matrix': cm
    }

# √âvaluation
results = evaluate_model(model, test_images, test_labels)
print(f"Accuracy: {results['accuracy']:.4f}")
print(f"Precision: {results['precision']:.4f}")
print(f"Recall: {results['recall']:.4f}")
print(f"F1-Score: {results['f1_score']:.4f}")
```

## üìà R√©sultats attendus

### M√©triques de performance
- **Accuracy** : >95%
- **Precision** : >94%
- **Recall** : >93%
- **F1-Score** : >94%

### Temps d'inf√©rence
```python
import time

def benchmark_inference(model, test_images, num_runs=100):
    """Benchmark du temps d'inf√©rence"""
    times = []
    
    for _ in range(num_runs):
        start_time = time.time()
        _ = model.predict(test_images[:1], verbose=0)
        end_time = time.time()
        times.append(end_time - start_time)
    
    avg_time = np.mean(times)
    std_time = np.std(times)
    
    return avg_time, std_time

# Benchmark
avg_time, std_time = benchmark_inference(model, test_images)
print(f"Temps d'inf√©rence moyen: {avg_time*1000:.2f}ms")
print(f"√âcart-type: {std_time*1000:.2f}ms")
```

## üîç Visualisation des r√©sultats

### Graphiques de performance
```python
import matplotlib.pyplot as plt
import seaborn as sns

def plot_training_history(history):
    """Affiche l'historique d'entra√Ænement"""
    fig, axes = plt.subplots(2, 2, figsize=(15, 10))
    
    # Accuracy
    axes[0, 0].plot(history.history['accuracy'], label='Training')
    axes[0, 0].plot(history.history['val_accuracy'], label='Validation')
    axes[0, 0].set_title('Model Accuracy')
    axes[0, 0].set_xlabel('Epoch')
    axes[0, 0].set_ylabel('Accuracy')
    axes[0, 0].legend()
    
    # Loss
    axes[0, 1].plot(history.history['loss'], label='Training')
    axes[0, 1].plot(history.history['val_loss'], label='Validation')
    axes[0, 1].set_title('Model Loss')
    axes[0, 1].set_xlabel('Epoch')
    axes[0, 1].set_ylabel('Loss')
    axes[0, 1].legend()
    
    # Matrice de confusion
    sns.heatmap(results['confusion_matrix'], annot=True, fmt='d', ax=axes[1, 0])
    axes[1, 0].set_title('Confusion Matrix')
    
    # M√©triques
    metrics = ['Accuracy', 'Precision', 'Recall', 'F1-Score']
    values = [results['accuracy'], results['precision'], 
              results['recall'], results['f1_score']]
    axes[1, 1].bar(metrics, values)
    axes[1, 1].set_title('Performance Metrics')
    axes[1, 1].set_ylabel('Score')
    
    plt.tight_layout()
    plt.show()

# Affichage des r√©sultats
plot_training_history(history)
```

### Analyse des erreurs
```python
def analyze_errors(model, test_images, test_labels, class_names):
    """Analyse les erreurs de classification"""
    predictions = model.predict(test_images)
    predicted_classes = np.argmax(predictions, axis=1)
    true_classes = np.argmax(test_labels, axis=1)
    
    # Indices des erreurs
    error_indices = np.where(predicted_classes != true_classes)[0]
    
    print(f"Nombre d'erreurs: {len(error_indices)}")
    print(f"Taux d'erreur: {len(error_indices)/len(test_images)*100:.2f}%")
    
    # Analyse des erreurs par classe
    error_analysis = {}
    for idx in error_indices:
        true_class = class_names[true_classes[idx]]
        pred_class = class_names[predicted_classes[idx]]
        
        if true_class not in error_analysis:
            error_analysis[true_class] = {}
        if pred_class not in error_analysis[true_class]:
            error_analysis[true_class][pred_class] = 0
        error_analysis[true_class][pred_class] += 1
    
    return error_analysis
```

## üö® D√©pannage

### Probl√®mes courants

#### 1. Overfitting
```python
# Techniques de r√©gularisation
model = keras.Sequential([
    base_model,
    keras.layers.GlobalAveragePooling2D(),
    keras.layers.Dropout(0.5),  # Augmenter le dropout
    keras.layers.Dense(128, activation='relu'),
    keras.layers.BatchNormalization(),  # Ajouter BatchNorm
    keras.layers.Dropout(0.5),
    keras.layers.Dense(num_classes, activation='softmax')
])

# Augmentation de donn√©es
datagen = keras.preprocessing.image.ImageDataGenerator(
    rotation_range=20,
    width_shift_range=0.2,
    height_shift_range=0.2,
    horizontal_flip=True,
    zoom_range=0.2
)
```

#### 2. Underfitting
```python
# Augmentation de la complexit√©
model = keras.Sequential([
    base_model,
    keras.layers.GlobalAveragePooling2D(),
    keras.layers.Dense(512, activation='relu'),  # Plus de neurones
    keras.layers.Dense(256, activation='relu'),
    keras.layers.Dense(num_classes, activation='softmax')
])

# R√©duction du learning rate
optimizer = keras.optimizers.Adam(learning_rate=0.0001)
```

#### 3. Probl√®me de m√©moire
```python
# R√©duction de la taille du batch
BATCH_SIZE = 16  # Au lieu de 32

# Utilisation de la m√©moire GPU
gpus = tf.config.experimental.list_physical_devices('GPU')
if gpus:
    tf.config.experimental.set_memory_growth(gpus[0], True)
```

## üìù Rapport de test

### R√©sum√© des performances
- **Dur√©e d'entra√Ænement** : 2h 30min
- **Nombre d'√©poques** : 45
- **Taille du mod√®le** : 8.5MB
- **Temps d'inf√©rence** : 85ms

### Recommandations
1. **Optimisation** : Quantification pour r√©duire la taille
2. **Augmentation** : Plus de donn√©es d'entra√Ænement
3. **Architecture** : Test d'autres mod√®les de base
4. **D√©ploiement** : Conversion pour l'inf√©rence mobile

## üîÑ Tests de suivi

### Test de robustesse
- **Bruit** : Ajout de bruit gaussien
- **Rotation** : Tests de rotation d'images
- **√âclairage** : Variations d'√©clairage
- **Occlusion** : Masquage partiel des objets

### Test de g√©n√©ralisation
- **Cross-validation** : Validation crois√©e
- **Donn√©es non vues** : Test sur nouveau dataset
- **Transfer learning** : Adaptation √† d'autres domaines

---

*Test r√©alis√© le : [Date]*
*Responsable : [Nom]*
*Statut : ‚úÖ R√©ussi*
